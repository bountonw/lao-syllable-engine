# Lao Syllable Engine

> âš ï¸ This project is in its early stages. The goal is to develop a rule-based Lao syllable segmentation
> engine that can support text segmentation, typesetting, spellchecking, and other NLP applications.
> The outline below represents a planned framework for syllable classification based on phonotactic
> structure, vowel behavior, and consonant clustering. It does not yet reflect a complete implementation
> and will continue to evolve.

## Overview

A linguistically accurate Lao syllable segmentation engine. This library parses unsegmented Lao text into valid syllables using rule-based phonotactic logic, with optional dictionary enhancement. It is designed to be modular, portable, and embeddable in larger pipelines for typesetting, spellchecking, translation, and natural language processing (NLP).

---

## ğŸ” Purpose

Lao does not use spaces between words. To break lines correctly or process text linguistically, software must recognize **legal syllable boundaries**. This engine:

* Validates individual syllables using character-level phonotactic rules
# Lao Syllable Engine

A linguistically accurate Lao syllable segmentation engine. This library parses unsegmented Lao text into valid syllables using rule-based phonotactic logic, with optional dictionary enhancement. It is designed to be modular, portable, and embeddable in larger pipelines for typesetting, spellchecking, translation, and natural language processing (NLP).

---

## ğŸ” Purpose

Lao does not use spaces between words. To break lines correctly or process text linguistically, software must recognize **legal syllable boundaries**. This engine:

* Validates individual syllables using character-level phonotactic rules
* Segments strings into syllables using longest-match-first logic
* Supports real-world edge cases (clusters, tonal forms, AM, short vowels, etc.)
* Can be used for word segmentation, typesetting, and spellchecking

---

## ğŸ“¦ Features

* Accurate syllable validation
* Rule-based engine (not regex spaghetti)
* Optional dictionary-based lookup for maximal matching
* Designed in Python for performance and future Elixir porting
* Modular 

---

## ğŸ“‚ Project Structure

```
lao-syllable-engine/
â”œâ”€â”€ py/
â”‚   â””â”€â”€ syllable_engine/
â”‚       â”œâ”€â”€ validate.py
â”‚       â””â”€â”€ ...
â”œâ”€â”€ elixir/
â”œâ”€â”€ rust/
â”œâ”€â”€ docs/                     # â† Human-readable rule documentation
â”‚   â”œâ”€â”€ syllable_structure.md
â”‚   â”œâ”€â”€ cluster_rules.md
â”‚   â””â”€â”€ vowel_system.md
â”œâ”€â”€ data/                     # â† Machine-readable language files
â”‚   â”œâ”€â”€ lao_syllables.txt
â”‚   â”œâ”€â”€ lao_dictionary.tsv
â”‚   â”œâ”€â”€ fallback_rules.json
â”‚   â””â”€â”€ segmentation_tests.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
```

---

## ğŸš€ Usage (Python)

```python
from syllable_engine import segment, validate

syllables = segment("\u0e84\u0ebb\u0ab9\u0ea5\u0eb2\u0ea7\u0ea1\u0eb1\u0e81\u0ead\u0ec8\u0eb2\u0ab9\u0ebb\u0ec8")
# â†’ ['àº„àº»àª¹', 'àº¥àº²àº§', 'àº¡àº±àº', 'àº­à»ˆàº²àª¹', 'àº»à»ˆ']

is_valid = validate("\u0e97\u0eb3")  # â†’ True
```

---

## ğŸ“š Goals

* ğŸ’¡ Provide a standalone, linguistically grounded Lao syllable parser
* âš¡ Port to Elixir for scalable, high-performance use
* ğŸ’ª Serve as a foundation for spellcheckers, NLP tools, and TeXLive enhancements
* â†» Integrate into Markdown â†’ PDF/HTML/EPUB/LaTeX pipelines

---

## ğŸ¤ Contributing

We welcome linguists, developers, and native Lao speakers interested in improving syllable parsing, dictionary accuracy, or rule refinement. See `tests/` for guidance.

---

## ğŸ“œ License

MIT â€” free for personal, academic, and commercial use.
* Segments strings into syllables using longest-match-first logic
* Supports real-world edge cases (clusters, tonal forms, AM, short vowels, etc.)
* Can be used for word segmentation, typesetting, and spellchecking

---

## ğŸ“¦ Features

* Accurate syllable validation (àº„àº»àª¹, àºàº°, àº—àº³, à¸ˆàº°, à»€àº«àº»à»‰àº²)
* Rule-based engine (not regex spaghetti)
* Optional dictionary-based lookup for maximal matching
* Designed for performance and future Elixir porting
* Modular â€” can be called from Markdown â†’ TeX, HTML, EPUB, DOCX, etc.

---

## ğŸ“‚ Project Structure

```
syllable_engine/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ segment.py         # longest-match-first segmentation logic
â”œâ”€â”€ validate.py        # is_valid_syllable(), rule enforcement
â”œâ”€â”€ constants.py       # V_PRE_SET, C_BASE_SET, clusters, tone marks, etc.
â”œâ”€â”€ rules.py           # phonotactic model (syllable types)
â””â”€â”€ tests/
    â””â”€â”€ test_engine.py
```

---

## ğŸš€ Usage (Python)

```python
from syllable_engine import segment, validate

syllables = segment("\u0e84\u0ebb\u0ab9\u0ea5\u0eb2\u0ea7\u0ea1\u0eb1\u0e81\u0ead\u0ec8\u0eb2\u0ab9\u0ebb\u0ec8")
# â†’ ['àº„àº»àª¹', 'àº¥àº²àº§', 'àº¡àº±àº', 'àº­à»ˆàº²àª¹', 'àº»à»ˆ']

is_valid = validate("\u0e97\u0eb3")  # â†’ True
```

---

## ğŸ“š Goals

* ğŸ’¡ Provide a standalone, linguistically grounded Lao syllable parser
* âš¡ Port to Elixir for scalable, high-performance use
* ğŸ’ª Serve as a foundation for spellcheckers, NLP tools, and TeXLive enhancements
* â†» Integrate into Markdown â†’ PDF/HTML/EPUB/LaTeX pipelines

---

## ğŸ¤ Contributing

We welcome linguists, developers, and native Lao speakers interested in improving syllable parsing, dictionary accuracy, or rule refinement. See `tests/` for guidance.

---

## ğŸ“œ License

MIT â€” free for personal, academic, and commercial use.

